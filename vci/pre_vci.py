import argparse
import os
import shutil
import json
from PIL import Image
from tqdm import tqdm
import torch
from torchvision.transforms.functional import to_tensor, to_pil_image

import numpy as np

# dont question this ... :/
from pathlib import Path
import sys
path_root = Path(__file__).parents[1]
sys.path.append(str(path_root))

# from script.thirdparty.colmap_database_3_9 import *
from script.thirdparty.colmap_database_3_10 import *
from script.downsample_point import process_ply_file
from utils.pose_utils import rotmat2qvec, qvec2rotmat
from vci.pose_utils import *
from vci.sys_utils import *
from vci.colmap_utils import run_colmap_poses, run_colmap_mapper

from submodules.BackgroundMattingV2.model.model import MattingRefine

# Helper functions
def load_paths(args: argparse.Namespace) -> dict[str, str]:
	paths: dict[str, str] = {}

	paths['base'] = args.source_path
	paths['calibration'] = os.path.join(paths['base'], args.calibration_file) # Will discard paths['base'] if args.calibration_file is an absolute path

	paths['bg_src'] = os.path.join(paths['base'], "background", "rgb")

	paths['colmap'] = os.path.join(paths['base'], "colmap")

	paths['masks'] = os.path.join(paths['colmap'], "masks")
	paths['input'] = os.path.join(paths['colmap'], "input")
	paths['distorted'] = os.path.join(paths['colmap'], "distorted")
	paths['manual'] = os.path.join(paths['colmap'], "manual")

	paths['imagestxt'] = os.path.join(paths['manual'], "images.txt")
	paths['camerastxt'] = os.path.join(paths['manual'], "cameras.txt")
	paths['points3Dtxt'] = os.path.join(paths['manual'], "points3D.txt")

	if args.gaussian_splatting:
		paths['db'] = os.path.join(paths['distorted'], "database.db")

		paths['sparse'] = os.path.join(paths['distorted'], "sparse", "0")
		paths['dense'] = paths['colmap']
	else:
		paths['db'] = os.path.join(paths['colmap'], "database.db")
		
		paths['sparse'] = os.path.join(paths['distorted'], "sparse")
		paths['dense'] = os.path.join(paths['colmap'], "dense", "workspace")

	paths['undistorted_images'] = os.path.join(paths['dense'], "images")
	paths['output'] = os.path.join(paths['dense'], "fused.ply")
	paths['output_downsample'] = os.path.join(paths['base'], "points3D_downsample.ply")

	return paths

def cam_name(idx: int) -> str:
	return "cam" + str(idx).zfill(2)

def create_name_mapping(paths: dict[str, str]) -> dict[str, str]:
	mapping = {}

	cams = sorted(os.listdir(os.path.join(paths['base'], "frame_00000", "rgb"))) # C0000.jpg, C0001.jpg, ...

	for i, cam in enumerate(cams):
		camera_name = os.path.splitext(cam)[0]
		mapping[cam] = cam_name(i)
		mapping[camera_name] = cam_name(i)

	return mapping

def rotate_image(image, rotation):
	if rotation == 1:
		return image.transpose(Image.ROTATE_90)
	elif rotation == 2:
		return image.transpose(Image.ROTATE_180)
	elif rotation == 3:
		return image.transpose(Image.ROTATE_270)
	else:
		return image

def mask_image(img_src, bg_src, model):
	with torch.no_grad():
		mask, img = model(img_src, bg_src)[:2]
		img = img * mask

		return torch.concatenate((img[0], mask[0]))


# Main functionality
def prepare_input_images_ed3dgs(paths: dict[str, str], args: argparse.Namespace, name_mapping: dict[str, str]) -> tuple[int, int]:
	"""
	Extract all given input images and copy them for E-D3DGS to use, sorted by camera. Optionally,
	images are masked and/or rotated.

	Params:
		paths (dict[str, str]):        A dictionary containing the filepaths
		args (argparse.Namespace):     The command line arguments generated by argparse
		name_mapping (dict[str, str]): A dictionary mapping the canonical image names to ordered camera names

	Returns:
		nums (tuple[int, int]): The number of frames and the number of cameras
	"""

	frames = sorted([f for f in os.listdir(paths['base']) if f.startswith("frame")]) # Directory names (frame_00000, frame_00001, ...)
	cameras = sorted([f for f in os.listdir(os.path.join(paths['base'], frames[0], "rgb"))]) # Camera file names (C0000.jpg, C0001.jpg, ...)

	num_frames = len(frames)
	num_cams = len(cameras)

	print(f"Number of frames: {num_frames}")
	print(f"Number of cameras: {num_cams}")
	print(f"Total number of images: {num_frames * num_cams}")
	print()

	# Read background images
	bg_paths = [os.path.join(paths['bg_src'], bg) for bg in sorted(os.listdir(paths['bg_src']))]
	bgs = [to_tensor(Image.open(path)).cuda().unsqueeze(0) for path in bg_paths]

	# bgs may only be empty if --remove_background is not set
	assert not (len(bgs) == 0 and args.remove_background)

	# Create image dir
	if not create_dir(os.path.join(paths['base'], "images")):
		print("E-D3DGS input directory already exists. Skipping image extraction.")
		return num_frames, num_cams
	
	# Create cam dirs (images/cam00, images/cam01, ...)
	for j, cam in enumerate(cameras):
		create_dir(os.path.join(paths['base'], "images", name_mapping[cam]))

	if args.remove_background:
		# Load model for removing the backgrounds
		model = MattingRefine(backbone="mobilenetv2", backbone_scale=0.25, refine_mode="sampling", refine_sample_pixels=80000)

		model.load_state_dict(torch.load("pytorch_mobilenetv2.pth", weights_only=True))
		model = model.eval().to(torch.float32).to(torch.device("cuda"))
	
	if args.rotate_images:
		rotations = { "C0000": 3, "C0001": 1, "C0004": 3, "C0005": 3, "C0006": 3, "C0007": 3, "C0008": 3, "C0010": 1, "C0012": 3, "C0013": 3, "C0014": 3, "C0016": 3, "C0018": 3, "C0020": 1, "C0021": 1, "C0022": 1, "C0024": 1, "C0025": 1, "C0026": 3, "C0028": 3, "C0029": 3, "C0030": 1, "C0031": 1, "C0034": 3, "C0037": 1, "C0038": 3, "C0039": 1, "C1000": 1, "C1001": 1, "C1002": 1, "C1004": 1, "C1005": 1 }

	# Process images and copy them to cam dirs
	progress_bar = tqdm(desc="Processing images", total=num_frames*num_cams)

	for i, frame in enumerate(frames):
		for j, cam in enumerate(cameras):
			camera_name = os.path.splitext(cam)[0] # C0000, C0001, ...
			progress_bar.set_postfix({ "Cam": camera_name, "Img": i })

			src_path = os.path.join(paths['base'], frame, "rgb", cam)
			dst_path = os.path.join(paths['base'], "images", name_mapping[cam], str(i).zfill(4))

			if not args.remove_background and not args.rotate_images:
				# If images are not modified, just copying them is a lot faster
				shutil.copyfile(src_path, dst_path + ".jpg")
			else:
				img = Image.open(src_path)

				if args.remove_background:
					img_tensor = to_tensor(img).cuda().unsqueeze(0)
					masked_tensor = mask_image(img_tensor, bgs[j], model)
					img = to_pil_image(masked_tensor.cpu())

				if args.rotate_images:
					img = rotate_image(img, rotations[camera_name])

				img.save(dst_path + ".png")

			progress_bar.update()
	progress_bar.close()

	return num_frames, num_cams

def prepare_input_images_colmap(paths: dict[str, str], args: argparse.Namespace, name_mapping: dict[str, str]) -> tuple[list[str], list[str]]:
	"""
	Extract the images from the first frame for COLMAP. Optionally, the images are masked and/or
	rotated.

	Params:
		paths (dict[str, str]):        A dictionary containing the filepaths
		args (argparse.Namespace):     The command line arguments generated by argparse
		name_mapping (dict[str, str]): A dictionary mapping the canonical image names to ordered camera names

	Returns:
		files (tuple[list[str], list[str]]): The names of the extracted images and backgrounds
	"""

	img_path = os.path.join(paths['base'], "frame_00000", "rgb")
	images = sorted(os.listdir(img_path))
	bgs = sorted(os.listdir(paths['bg_src']))

	images_exist = not create_dir(paths['input'])
	masks_exist = not create_dir(paths['masks'])

	if images_exist and (masks_exist or not args.remove_background):
		print("Image and mask directories already exist. Skipping image extraction (if this is undesired, use --replace_images)")
		return (images, bgs)

	if args.remove_background:
		model = MattingRefine(backbone="mobilenetv2", backbone_scale=0.25, refine_mode="sampling", refine_sample_pixels=80000)

		model.load_state_dict(torch.load("pytorch_mobilenetv2.pth", weights_only=True))
		model = model.eval().to(torch.float32).to(torch.device("cuda"))

	if args.rotate_images:
		rotations = { "C0000": 3, "C0001": 1, "C0004": 3, "C0005": 3, "C0006": 3, "C0007": 3, "C0008": 3, "C0010": 1, "C0012": 3, "C0013": 3, "C0014": 3, "C0016": 3, "C0018": 3, "C0020": 1, "C0021": 1, "C0022": 1, "C0024": 1, "C0025": 1, "C0026": 3, "C0028": 3, "C0029": 3, "C0030": 1, "C0031": 1, "C0034": 3, "C0037": 1, "C0038": 3, "C0039": 1, "C1000": 1, "C1001": 1, "C1002": 1, "C1004": 1, "C1005": 1 }

	for i, img_name in tqdm(enumerate(images), "Preparing input images", total=len(images)):
		camera_name = os.path.splitext(img_name)[0]
		img = Image.open(os.path.join(img_path, img_name))

		if args.rotate_images:
			img = rotate_image(img, rotations[camera_name])

		if args.remove_background:
			bg = Image.open(os.path.join(paths['bg_src'], img_name))

			if args.rotate_images:
				bg = rotate_image(bg, rotations[camera_name])

			img_tensor = to_tensor(img).cuda().unsqueeze(0)
			bg_tensor = to_tensor(bg).cuda().unsqueeze(0)

			mask_tensor = mask_image(img_tensor, bg_tensor, model)[3] # We only need the alpha channel (the mask)

			mask = to_pil_image(mask_tensor.cpu())
			mask.save(os.path.join(paths['masks'], name_mapping[camera_name] + ".jpg.png"))

		img.save(os.path.join(paths['input'], name_mapping[camera_name] + ".jpg"))

	return images, bgs

def extract_poses(paths: dict[str, str], args: argparse.Namespace, name_mapping: dict[str, str]) -> None:
	"""
	Extracts camera pose information from paths['calibration']. The poses will be written 
	to the sqlite database located at paths['db'] and to the .txt files located in the directory
	paths['manual']. The generated files can be processed directly by COLMAP.
	
	Params:
		paths (dict[str, str]):        A dictionary containing the filepaths
		args (argparse.Namespace):     The command line arguments generated by argparse
		name_mapping (dict[str, str]): A dictionary mapping the canonical image names to ordered camera names

	Returns:
		None
	"""

	# Set camera model
	camera_models = {"SIMPLE_PINHOLE": 0, "PINHOLE": 1, "SIMPLE_RADIAL": 2, "RADIAL": 3, "OPENCV": 4, "RADIAL_FISHEYE": 9 }
	camera_model = camera_models[args.camera]

	# Load calibration file
	assert os.path.exists(paths['calibration'])
	calibration_file = open(paths['calibration'])
	calibration = json.load(calibration_file)
	calibration_file.close()

	# Create necessary directories
	db_dir = os.path.dirname(paths['db'])
	create_dir(db_dir)
	create_dir(paths['manual'])

	imagetxt_list = []
	cameratxt_list = []

	db = COLMAPDatabase.connect(paths['db'])
	db.create_tables()

	print(f"Start writing to new database at '{paths['db']}'")

	available_cams = os.listdir(paths['input'])
	cam_idx = 0

	for i, camera in tqdm(enumerate(calibration["cameras"]), desc="Reading camera calibration", total=len(calibration['cameras'])):
		# Find corresponding images
		camera_name = camera["camera_id"]

		if not camera_name in available_cams:
			camera_name = name_mapping.get(camera_name, "") + ".jpg"

			if not camera_name in available_cams:
				print(f"Missing image source for camera {camera['camera_id']}. Skipping this camera.")
				continue

		image_name = camera_name

		img = Image.open(os.path.join(paths['input'], image_name))
		width, height = img.size

		# Extract pose information from the JSON file
		view_matrix = np.array(camera["extrinsics"]["view_matrix"], dtype=np.float64).reshape((4, 4)) # View Matrix is given in World-To-Camera Space (i think)

		camera_matrix = np.array(camera["intrinsics"]["camera_matrix"], dtype=np.float64).reshape((3, 3))

		if not args.camera in ["PINHOLE", "SIMPLE_PINHOLE"]:
			distortion_coefficients = np.array(camera["intrinsics"]["distortion_coefficients"], dtype=np.float64)

		# Camera rotation and translation
		R = view_matrix[:3, :3]
		T = view_matrix[:3, 3]
		Q = rotmat2qvec(R)

		# focal length
		f_x = camera_matrix[0, 0]
		f_y = camera_matrix[1, 1]

		# principal point
		c_x = camera_matrix[0, 2]
		c_y = camera_matrix[1, 2]
		
		# Correct the parameters if a camera has incorrect values for some reason...
		json_width = int(camera["intrinsics"]["resolution"][0])
		json_height = int(camera["intrinsics"]["resolution"][1])

		if json_width != width or json_height != height:
			x_correction = float(width) / float(json_width)
			y_correction = float(height) / float(json_height)

			f_x *= x_correction
			f_y *= y_correction
			c_x *= x_correction
			c_y *= y_correction

		# Write camera and image data into database
		if args.camera == "SIMPLE_PINHOLE":
			params = np.array([f_x, c_x, c_y])
		elif args.camera == "PINHOLE":
			params = np.array([f_x, f_y, c_x, c_y])
		elif args.camera == "OPENCV":
			params = np.array([f_x, f_y, c_x, c_y, 0, 0, 0, 0])
			# params = np.array([f_x, f_y, c_x, c_y, distortion_coefficients[0], distortion_coefficients[1], distortion_coefficients[2], distortion_coefficients[3]])
		elif args.camera == "RADIAL":
			params = np.array([f_x, c_x, c_y, 0, 0])
			# params = np.array([f_x, c_x, c_y, distortion_coefficients[0], distortion_coefficients[1]])
		elif args.camera == "RADIAL_FISHEYE":
			params = np.array([f_x, c_x, c_y, 0, 0])
			# params = np.array([f_x, c_x, c_y, distortion_coefficients[0], distortion_coefficients[1]])

		camera_id = db.add_camera(camera_model, width, height, params)

		# image_id = db.add_image(image_name, camera_id, Q, T, image_id=i+1) # For COLMAP <= 3.9
		image_id = db.add_image(image_name, camera_id, image_id=i+1) # For COLMAP >= 3.10

		db.commit()

		# Append lines for images.txt and cameras.txt
		Q_string = " ".join([str(q) for q in Q])
		T_string = " ".join([str(t) for t in T])
		params_string = " ".join([str(num) for num in params])

		image_line = f"{image_id} {Q_string} {T_string} {camera_id} {image_name}\n"
		imagetxt_list.append(image_line)
		imagetxt_list.append("\n")

		camera_line = f"{camera_id} {args.camera} {width} {height} {params_string}\n"
		cameratxt_list.append(camera_line)
		
		cam_idx += 1

	db.close()

	print("Done writing to database")
	
	# Write prepared data into images.txt and cameras.txt
	write_lines_to_file(imagetxt_list, paths['imagestxt'])
	write_lines_to_file(cameratxt_list, paths['camerastxt'])
	write_lines_to_file([], paths['points3Dtxt'])

	print("Done writing text output")


def main():
	parser = argparse.ArgumentParser(prog="python pre_vci.py", description="Generates a sparse/dense point cloud from a set of input images and camera poses generated by the VCI")
	parser.add_argument("--source_path", "-s", default="", type=str, required=True, help="the path where the image files are located")
	parser.add_argument("--calibration_file", "-c", default="calibration.json", type=str, help="the path to the camera calibration file, ignored when --use_mapper is set (default: %(default)s)")
	parser.add_argument("--camera", default="PINHOLE", type=str, choices=["SIMPLE_PINHOLE", "PINHOLE", "OPENCV", "SIMPLE_RADIAL", "RADIAL", "RADIAL_FISHEYE"], help="the camera model used when extracting the poses (default: %(default)s)")
	parser.add_argument("--use_mapper", action="store_true", default=False, help="use the COLMAP mapper to extract the camera poses and ignore the calibration file (default: %(default)s)")
	parser.add_argument("--replace_images", action="store_true", default=False, help="delete previously generated input images and replace them by newly generated ones (default: %(default)s)")
	parser.add_argument("--gaussian_splatting", action="store_true", default=False, help="enable output for 3d gaussian splatting (default: %(default)s)")
	parser.add_argument("--skip_dense", action="store_true", default=False, help="skip dense reconstruction (True when --gaussian_splatting is set, default: %(default)s)")
	parser.add_argument("--remove_background", action="store_true", default=False, help="use BackgroundMattingV2 to remove the background (default: %(default)s)")
	parser.add_argument("--rotate_images", action="store_true", default=False, help="rotate the input images correctly (True when --use_mapper is set, default: %(default)s)")
	args = parser.parse_args()

	if args.gaussian_splatting:
		args.skip_dense = True

	if args.use_mapper:
		args.rotate_images = True

	# Load all the paths from the passed arguments
	paths = load_paths(args)
	assert os.path.exists(paths['base'])

	# Print out the paths
	print("Set directories:")
	for k, v in paths.items():
		print(f"{k:<20} -> {v}")
	print()

	# Remove old files and directories
	if os.path.exists(paths['colmap']):
		whitelist: list[str] = []
		if not args.replace_images:
			whitelist = [paths['input'], paths['masks']]

		removed = clear_directory(paths['colmap'], whitelist)
		print("Removed files and directories:")
		print("\n".join(removed))
		print()

	print(f"Preparing data from '{paths['base']}'")
	print()

	name_mapping = create_name_mapping(paths)

	prepare_input_images_ed3dgs(paths, args, name_mapping)

	images, bgs = prepare_input_images_colmap(paths, args, name_mapping)

	if not args.use_mapper:
		extract_poses(paths, args, name_mapping)
		run_colmap_poses(paths, args)
	else:
		run_colmap_mapper(paths, args)

	if not args.skip_dense:
		process_ply_file(paths['output'], paths['output_downsample'])

if __name__ == "__main__":
	main()