import argparse
import os
import glob
import shutil
import numpy as np
import json
from PIL import Image, ImageChops
from tqdm import tqdm

# dont question this ... :/
from pathlib import Path
import sys
path_root = Path(__file__).parents[1]
sys.path.append(str(path_root))

from script.thirdparty.colmap_database_3_9 import *
#from vci.COLMAPDatabase import *
from vci.pose_utils import *
from vci.sys_utils import *

# Helper functions
def load_paths(args: argparse.Namespace) -> dict[str, str]:
	paths: dict[str, str] = {}

	paths['base'] = args.source_path
	paths['calibration'] = os.path.join(paths['base'], args.calibration_file)

	if args.mask_source == "":
		paths['mask_source'] = paths['base']
	else:
		paths['mask_source'] = args.mask_source

	paths['colmap'] = os.path.join(paths['base'], "colmap")

	paths['masks'] = os.path.join(paths['colmap'], "masks")
	paths['input'] = os.path.join(paths['colmap'], "input")
	paths['distorted'] = os.path.join(paths['colmap'], "distorted")
	paths['manual'] = os.path.join(paths['colmap'], "manual")

	paths['imagestxt'] = os.path.join(paths['manual'], "images.txt")
	paths['camerastxt'] = os.path.join(paths['manual'], "cameras.txt")
	paths['points3Dtxt'] = os.path.join(paths['manual'], "points3D.txt")

	if args.gaussian_splatting:
		paths['db'] = os.path.join(paths['distorted'], "database.db")

		paths['sparse'] = os.path.join(paths['distorted'], "sparse", "0")
		paths['dense'] = paths['colmap']
	else:
		paths['db'] = os.path.join(paths['colmap'], "database.db")
		
		paths['sparse'] = os.path.join(paths['distorted'], "sparse")
		paths['dense'] = os.path.join(paths['colmap'], "dense", "workspace")

	paths['output'] = os.path.join(paths['dense'], "fused.ply")
	paths['undistorted_images'] = os.path.join(paths['dense'], "images")

	return paths

# Main functionality
def extract_images(paths: dict[str, str], args: argparse.Namespace) -> tuple[list[str], list[str]]:
	valid_filetypes = [".png", ".jpg"]

	images = sorted([file for file in os.listdir(paths['base']) if os.path.splitext(file)[1] in valid_filetypes and "mask" not in file])
	masks = sorted([file for file in os.listdir(paths['mask_source']) if os.path.splitext(file)[1] in valid_filetypes and "mask" in file])

	print(f"Found {len(images)} images and {len(masks)} masks")

	if len(images) == 0:
		print("Skipping image extraction")
		return (images, masks)
	
	copy_images = create_dir(paths['input'])
	copy_masks = create_dir(paths['masks']) and args.use_masks

	if not copy_images and not copy_masks:
		print("Image and mask directories already exist. Skipping image extraction (if this is undesired, use --replace_images)")
		return (images, masks)

	downscale_factor = 1.0 / args.resolution

	for i, img_name in tqdm(enumerate(images), "Preparing input images", total=len(images)):
		mask_name = masks[i]

		img = Image.open(os.path.join(paths['base'], img_name))
		mask = Image.open(os.path.join(paths['mask_source'], mask_name))

		# Apply mask
		if args.use_masks:
			img = ImageChops.multiply(img, mask)

		if copy_images:
			img = scale_image(img, downscale_factor)
			img.save(os.path.join(paths['input'], img_name))

		if copy_masks:
			mask = scale_image(mask, downscale_factor)
			mask.save(os.path.join(paths['masks'], img_name + ".png")) # This is how COLMAP wants the masks

	return images, masks

def extract_poses(filenames: list[str], paths: dict[str, str], args: argparse.Namespace) -> None:
	"""
	Extracts camera pose information from paths['calibration']. The poses will be written 
	to the sqlite database located at paths['db'] and to the .txt files located in the directory
	paths['manual']. The generated files can be processed directly by COLMAP.
	
	Params:
		filenames (list[str]):     A list of the filenames of the image sources as returned by extract_images
		paths (dict[str, str]):    A dictionary containing the filepaths
		args (argparse.Namespace): The command line arguments generated by argparse

	Returns:
		None
	"""

	# Set camera model
	camera_models = {"PINHOLE": 1 , "OPENCV": 4 }
	if not args.camera in camera_models.keys():
		print(f"Unsupported camera model: {args.camera}")
		exit()

	camera_model = camera_models[args.camera]

	# Load calibration file
	assert os.path.exists(paths['calibration'])
	calibration_file = open(paths['calibration'])
	calibration = json.load(calibration_file)
	calibration_file.close()

	# Create necessary directories
	db_dir = os.path.dirname(paths['db'])
	create_dir(paths['manual'])
	create_dir(db_dir)

	imagetxt_list = []
	cameratxt_list = []

	# Delete old database
	if os.path.exists(paths['db']):
		print(f"Overwriting old input database at '{paths['db']}'")
		os.remove(paths['db'])

	db = COLMAPDatabase.connect(paths['db'])
	db.create_tables()

	print(f"Start writing to new database at '{paths['db']}'")

	for i, camera in tqdm(enumerate(calibration["cameras"]), desc="Reading camera calibration", total=len(calibration['cameras'])):
		# Downscale factor
		s = 1.0 / args.resolution

		# Find corresponding images
		camera_name = camera["camera_id"]
		matching_images = [f for f in filenames if camera_name in f]

		if len(matching_images) == 0:
			print(f"Missing image source for camera {camera_name}. Skipping this camera.")
			continue

		image_name = matching_images[0]

		img = Image.open(os.path.join(paths['input'], image_name))
		width, height = img.size

		# Extract pose information from the JSON file
		view_matrix = np.array(camera["extrinsics"]["view_matrix"]).reshape((4, 4)) # View Matrix is given in World-To-Camera Space (i think)
		view_matrix = rotate_z_view_matrix(view_matrix)

		camera_matrix = np.array(camera["intrinsics"]["camera_matrix"]).reshape((3, 3))

		distortion_coefficients = np.array(camera["intrinsics"]["distortion_coefficients"])

		# Camera rotation and translation
		R = view_matrix[:3, :3]
		T = view_matrix[:3, 3]
		Q = rotation_matrix_to_quaternion(R)

		# focal length
		f_x = camera_matrix[0, 0]
		f_y = camera_matrix[1, 1]

		# principal point
		c_x = camera_matrix[0, 2]
		c_y = camera_matrix[1, 2]
		
		# Correct parameters if a camera has incorrect values for some reason...
		json_width = int(camera["intrinsics"]["resolution"][0] * s)
		json_height = int(camera["intrinsics"]["resolution"][1] * s)

		if json_width != width or json_height != height:
			x_correction = float(width) / float(json_width)
			y_correction = float(height) / float(json_height)

			f_x *= x_correction
			f_y *= y_correction
			c_x *= x_correction
			c_y *= y_correction

		# Downscale
		f_x *= s
		f_y *= s

		c_x *= s
		c_y *= s

		# Write camera and image data into database
		params = np.array([f_x, f_y, c_x, c_y])

		if camera_model == 4: # OPENCV
			params = np.concatenate((params, distortion_coefficients[:4]))

		camera_id = db.add_camera(camera_model, width, height, params)

		image_id = db.add_image(image_name, camera_id, Q, T, image_id=i+1)
		#image_id = db.add_image(image_name, camera_id, image_id=i+1)

		db.commit()

		# Append lines for images.txt and cameras.txt
		Q_string = " ".join([str(q) for q in Q])
		T_string = " ".join([str(t) for t in T])
		params_string = " ".join([str(num) for num in params])

		image_line = f"{image_id} {Q_string} {T_string} {camera_id} {image_name}\n"

		imagetxt_list.append(image_line)
		imagetxt_list.append("\n")

		camera_line = f"{camera_id} {args.camera} {width} {height} {params_string}\n"
		cameratxt_list.append(camera_line)

	db.close()

	print("Done writing to database")
	
	# Write prepared data into images.txt and cameras.txt
	write_lines_to_file(imagetxt_list, paths['imagestxt'])
	write_lines_to_file(cameratxt_list, paths['camerastxt'])
	write_lines_to_file([], paths['points3Dtxt'])

	print("Done writing text output")

def run_colmap(image_names: list[str], paths: dict[str, str], args: argparse.Namespace) -> None:
	"""
	Executes the COLMAP command, producing a sparse or dense reconstruction of the
	input images.
	
	Params:
		image_names (list[str]):   A list of the filenames of the image sources as returned by extract_images
		paths (dict[str, str]):    A dictionary containg the filepaths
		args (argparse.Namespace): The command line arguments generated by argparse

	Returns:
		None
	"""

	# Create necessary directories
	create_dir(paths['sparse'])
	create_dir(paths['dense'])
	
	# Colmap commands
	print("Starting COLMAP...")
	print()

	feature_extract = f"colmap feature_extractor \
		--database_path {paths['db']} \
		--image_path {paths['input']}"
	# Pass masks to colmap so there are no points generated for the background
	if args.use_masks:
		feature_extract += f" --ImageReader.mask_path {paths['masks']}"
	exec_cmd(feature_extract)

	feature_matcher = f"colmap exhaustive_matcher \
		--database_path {paths['db']}" # --TwoViewGeometry.min_num_inliers 5
	exec_cmd(feature_matcher)

	tri_and_map = f"colmap point_triangulator \
		--database_path {paths['db']} \
		--image_path {paths['input']} \
		--input_path {paths['manual']} \
		--output_path {paths['sparse']} \
		--Mapper.ba_global_function_tolerance=0.000001" # --Mapper.min_num_matches 5 --Mapper.init_min_num_inliers 40 --Mapper.ba_global_function_tolerance=0.000001
	exec_cmd(tri_and_map)

	image_undistortion = f"colmap image_undistorter \
		--image_path {paths['input']} \
		--input_path {paths['sparse']} \
		--output_path {paths['dense']}"
	exec_cmd(image_undistortion)

	if not args.skip_dense:
		patch_match_stereo = f"colmap patch_match_stereo \
			--workspace_path {paths['dense']}"
		exec_cmd(patch_match_stereo)

		stereo_fusion = f"colmap stereo_fusion \
			--workspace_path {paths['dense']} \
			--output_path {paths['output']} \
			--StereoFusion.mask_path {paths['masks']}" # --StereoFusion.mask_path {mask_path}
		exec_cmd(stereo_fusion)

		print(f"All done! The output is in '{paths['output']}'")
	else:
		sparse = os.path.join(paths['dense'], "sparse")
		sparse0 = os.path.join(paths['dense'], "sparse", "0")

		files = os.listdir(sparse)
		create_dir(sparse0)

		# Copy each file from the source directory to the destination directory (required by 3DGS)
		for file in tqdm(files, desc=f"Moving output files", total=len(files)):
			if file == '0':
				continue

			source_file = os.path.join(sparse, file)
			destination_file = os.path.join(sparse0, file)
			shutil.move(source_file, destination_file)

	print("Done.")


def main():
	parser = argparse.ArgumentParser(prog="python pre_vci.py", description="Generates a sparse/dense point cloud from a set of input images and camera poses generated by the VCI")
	parser.add_argument("--source_path", "-s", default="", type=str, help="the path where the image files are located")
	parser.add_argument("--mask_source", default="", type=str, help="the path to the image masks (default: source_path)")
	parser.add_argument("--resolution", "-r", default=1, type=int, choices=[1,2,4,8], help="downscale the image by factor r")
	parser.add_argument("--replace_images", action="store_true", default=False, help="copies the images and masks into the input folder, replacing the old ones if necessary")
	parser.add_argument("--calibration_file", "-c", default="calibration.json", type=str, help="the name of the camera calibration file (default: %(default)s)")
	parser.add_argument("--gaussian_splatting", action="store_true", default=False, help="enables output for 3d gaussian splatting")
	parser.add_argument("--skip_dense", action="store_true", default=False, help="skips dense reconstruction (True when --gaussian_splatting is set, default: %(default)s)")
	parser.add_argument("--use_masks", action="store_true", default=False, help="enables usage of masks in the feature extractor")
	parser.add_argument("--camera", default="PINHOLE", type=str, choices=["OPENCV", "PINHOLE"], help="the camera model used when extracting the poses (default: %(default)s)")
	args = parser.parse_args()

	if args.gaussian_splatting:
		args.skip_dense = True

	# Load all the paths from the passed arguments
	paths = load_paths(args)
	assert os.path.exists(paths['base'])

	# Print out the paths
	print("Set directories:")
	for k, v in paths.items():
		print(f"{k:<20} -> {v}")
	print()

	# Remove old files and directories
	print("Removing previously generated COLMAP data...")

	whitelist: list[str] = []
	if not args.replace_images:
		whitelist = [paths['input'], paths['masks']]

	removed = clear_directory(paths['colmap'], whitelist)

	print("Removed files and directories:")
	print("\n".join(removed))
	print()

	print(f"Preparing data from '{paths['base']}'")
	print()

	images, masks = extract_images(paths, args)

	extract_poses(images, paths, args)

	run_colmap(images, paths, args)

if __name__ == "__main__":
	main()